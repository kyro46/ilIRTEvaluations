// English Language File
<!-- language file start -->

//general
tst_OpenCPU_table_title#:#Title
tst_OpenCPU_table_id#:#ID
tst_OpenCPUI_graph_IRCCC#:#Item Response Category Characteristic Curves
tst_OpenCPU_graph_IIC#:#Item Information Curves
tst_OpenCPU_graph_TIC#:#Test Information Curve
tst_OpenCPU_unreachable#:#The OpenCPU server is unreachable.
tst_OpenCPU_calculation_error#:#Not enough participants, answers or questions for an analysis.

//ilExteEvalOpenCPU
//config
tst_OpenCPU_server_title#:#OpenCPU URL
tst_OpenCPU_server_description#:#URL of the OpenCPU-Server - required IRT-packages for R have to be installed.</br>Recommended free server: https://cloud.opencpu.org
//table
tst_OpenCPU_title_long#:#Interactive R-console (OpenCPU)
tst_OpenCPU_title_short#:#Interactive R-console
tst_OpenCPU_description#:#IRT-Calculations via OpenCPU
tst_OpenCPU_callR#:#Execute with R
tst_OpenCPU_callR_desc#:#The test data is saved in variable <strong>"data"</strong>. Self-initiated operations via R can be performend here.<br/>

//ilExteEvalOpenCPUBaseData
tst_OpenCPUBaseData_title_long#:#Datamatrix for OpenCPU
tst_OpenCPUBaseData_title_short#:#Datamatrix for OpenCPU
tst_OpenCPUBaseData_description#:#Overview of the data which is sent to OpenCPU. Columns are questions, rows are participants.

//ilExteEvalOpenCPUAlpha
//config
tst_OpenCPUAlpha_min_qst_title#:#Minimum Questions
tst_OpenCPUAlpha_min_qst_description#:#Minimum number of questions in a test to calculate the internal consistency.
tst_OpenCPUAlpha_min_qst_alert#:#The test must have a minimum of %s questions to calculate the internal consistency.
tst_OpenCPUAlpha_min_part_title#:#Minimum Participants
tst_OpenCPUAlpha_min_part_description#:#Minimum participants of the test to to calculate the internal consistency.
tst_OpenCPUAlpha_min_part_alert#:#The test must have a minimum of %s participants to calculate the internal consistency.
tst_OpenCPUAlpha_min_difference_title#:#Accepted impact on overall consistency when removing an item
tst_OpenCPUAlpha_min_difference_description#:#The internal consistency can increase or decrease when a single item is removed. The acceptable range is given here. 
tst_OpenCPUAlpha_min_medium_title#:#Minimum 'mediocre'
tst_OpenCPUAlpha_min_medium_description#:#Minimum value rated as 'mediocre'. 0 to suppress the rating.
tst_OpenCPUAlpha_min_good_title#:#Minimum 'good'
tst_OpenCPUAlpha_min_good_description#:#Minimum value rated as 'good'. 0 to suppress the rating.
//table
tst_OpenCPUAlpha_title_long#:#Internal consistency (OpenCPU)
tst_OpenCPUAlpha_title_short#:#Internal consistency per item
tst_OpenCPUAlpha_description#:#Cronbach's Alpha, calculated after removing NA's (missing answers) via OpenCPU and the R-package "Latent Trait Models under IRT" (ltm)
tst_OpenCPUAlpha_table_alphaIfRemoved#:#Alpha if item is removed
tst_OpenCPUAlpha_table_alphaIfRemoved_difference#:#Difference
tst_OpenCPUAlpha_table_alphaIfRemoved_difference_comment#:#The more the internal consistency decreases without the item, the more important is it's contribution to the measurement. Low and negative values are desirable.
tst_OpenCPUAlpha_SpearmanBrownFormula#:#Spearmanâ€“Brown prediction formula
tst_OpenCPUAlpha_SpearmanBrownFormulaText#:#The test length might be changed by factor %1$s with comparable items to reach a reliability of at least %2$s (currently set threshold for "good quality").

//ilExteEvalOpenCPURawScoreDistribution
//table
tst_OpenCPURawScoreDistribution_title_long#:#Raw score distribution
tst_OpenCPURawScoreDistribution_title_short#:#Raw score distribution
tst_OpenCPURawScoreDistribution_description#:#Distribution, skewness and kurtosis
tst_OpenCPURawScoreDistribution_Plot#:#Raw score chart
tst_OpenCPURawScoreDistribution_skewness#:#Skewness
tst_OpenCPURawScoreDistribution_kurtosis#:#Kurtosis

//ilExteEvalOpenCPURasch
//table
tst_OpenCPURasch_title_long#:#IRT-Evaluations for tests with dichotomous Items (Rasch)
tst_OpenCPURasch_title_short#:#Dichotomous IRT (Rasch)
tst_OpenCPURasch_description#:#Rasch-Model (discrimination for all items fixed at 1). Polytomous Items will be dichotomized, meaning answers are categorized in "correct" and "wrong" at 50% of the reachable points.
tst_OpenCPURasch_table_RaschDiff#:#Difficulty

//ilExteEvalOpenCPU1PL
//table
tst_OpenCPU1PL_title_long#:#IRT-Evaluations for tests with dichotomous Items (1PL)
tst_OpenCPU1PL_title_short#:#Dichotomous IRT (1PL)
tst_OpenCPU1PL_description#:#1-PL-Model(common discrimination can differ from 1). Polytomous Items will be dichotomized, meaning answers are categorized in "correct" and "wrong" at 50% of the reachable points.
tst_OpenCPU1PL_table_1PLDiff#:#Difficulty
tst_OpenCPU1PL_table_1PLDisc#:#Discrimination

//ilExteEvalOpenCPU2PL
//table
tst_OpenCPU2PL_title_long#:#IRT-Evaluations for tests with dichotomous Items (2PL)
tst_OpenCPU2PL_title_short#:#Dichotomous IRT (2PL)
tst_OpenCPU2PL_description#:#Difficulty and discrimination are estimated per item. Polytomous Items will be dichotomized, meaning answers are categorized in "correct" and "wrong" at 50% of the reachable points.
tst_OpenCPU2PL_table_2PLDiff#:#Difficulty
tst_OpenCPU2PL_table_2PLDisc#:#Discrimination

//ilExteEvalOpenCPU3PL
//table
tst_OpenCPU3PL_title_long#:#IRT-Evaluations for tests with dichotomous Items (3PL)
tst_OpenCPU3PL_title_short#:#Dichotomous IRT (3PL)
tst_OpenCPU3PL_description#:#Difficulty, discrimination and guessing are estimated per item. Polytomous Items will be dichotomized, meaning answers are categorized in "correct" and "wrong" at 50% of the reachable points.
tst_OpenCPU3PL_table_3PLDiff#:#Difficulty
tst_OpenCPU3PL_table_3PLDisc#:#Discrimination
tst_OpenCPU3PL_table_3PLGues#:#Guessing

//ilExteEvalOpenCPUPolytomousGRM
//table
tst_OpenCPUPolytomousGRM_title_long#:#IRT-Evaluations for tests with polytomous Items (GRM)
tst_OpenCPUPolytomousGRM_title_short#:#Polytomous IRT (GRM)
tst_OpenCPUPolytomousGRM_description#:#GRM offers evaluation for items with partially correct answers. Each reached amount of points becomes an answercategory. Average difficulty is used to consolidate the categories in a single value (see <a href='http://doi.org/cpq2'>[DOI:10.1002/ets2.12065]</a>).
tst_OpenCPUPolytomousGRM_table_Diff#:#Mean difficulty
tst_OpenCPUPolytomousGRM_table_Disc#:#Discrimination

//ilExteEvalOpenCPUPolytomousGPCM
//table
tst_OpenCPUPolytomousGPCM_title_long#:#IRT-Evaluations for tests with polytomous Items (GPCM)
tst_OpenCPUPolytomousGPCM_title_short#:#Polytomous IRT (GPCM)
tst_OpenCPUPolytomousGPCM_description#:#GPCM offers evaluation for items with partially correct answers. Each reached amount of points becomes an answercategory. Average difficulty is used to consolidate the categories in a single value (see <a href='http://doi.org/cpq2'>[DOI:10.1002/ets2.12065]</a>).
tst_OpenCPUPolytomousGPCM_table_Diff#:#Mean difficulty
tst_OpenCPUPolytomousGPCM_table_Disc#:#Discrimination

//ilExteEvalOpenCPUFactorAnalysis
//table
tst_OpenCPUFactorAnalysis_title_long#:#Factor analysis
tst_OpenCPUFactorAnalysis_title_short#:#Factor analysis
tst_OpenCPUFactorAnalysis_description#:#This analysis shows the number of identified factors and the loadings per associated item.
tst_OpenCPUFactorAnalysis_graph_eigenvalues#:#Scree plot for eigenvalues
tst_OpenCPUFactorAnalysis_graph_eigenvalues_description#:#<br/>Up to %s factors are observable.
tst_OpenCPUFactorAnalysis_graph_factorloading#:#Factor loadings (%s factor solution)

//MIRT-Evaluations
//ilExteEvalOpenCPUPolytomousGRM_parameter
//table
tst_OpenCPUPolytomousGRM_parameter_title_long#:#Parameter and curve estimations for the Graded Response Model (GRM)
tst_OpenCPUPolytomousGRM_parameter_title_short#:#Parameter and curve estimations for the Graded Response Model (GRM)
tst_OpenCPUPolytomousGRM_parameter_description#:#The Graded Response Model (GRM) offers evaluation for items with partially correct answers. Each reached amount of points becomes an answercategory. Average difficulty is used to consolidate the categories in a single value (see <a href='http://doi.org/cpq2'>[DOI:10.1002/ets2.12065]</a>).
tst_OpenCPUPolytomousGRM_parameter_table_Diff#:#Mean difficulty
tst_OpenCPUPolytomousGRM_parameter_table_Disc#:#Discrimination
tst_OpenCPUPolytomousGRM_parameter_acc_TestinformationError#:#Test Information and Standard Error
tst_OpenCPUPolytomousGRM_parameter_acc_ICC#:#Item Tracelines
tst_OpenCPUPolytomousGRM_parameter_acc_expTotalScore#:#Expected Total Score

//ilExteEvalOpenCPUPolytomousGRM_modelfit
//table
tst_OpenCPUPolytomousGRM_modelfit_title_long#:#Model-fit: applicability of the Graded Response Model 
tst_OpenCPUPolytomousGRM_modelfit_title_short#:Model-fit: applicability of the Graded Response Model 
tst_OpenCPUPolytomousGRM_modelfit_description#:#Fit statistics to check the applicabilit of the Graded Response Model for the whole test

//tst_OpenCPUPolytomousGRM_itemfit
//table
tst_OpenCPUPolytomousGRM_itemfit_title_long#:#Item-fit: applicability of the Graded Response Model per item
tst_OpenCPUPolytomousGRM_itemfit_title_short#:#Item-fit: applicability of the Graded Response Model per item
tst_OpenCPUPolytomousGRM_itemfit_description#:#Fit statistics to check the applicabilit of the Graded Response Model for specific items in this test
tst_OpenCPUPolytomousGRM_itemfit_table_outfit#:#outfit
tst_OpenCPUPolytomousGRM_itemfit_table_z.outfit#:#z.outfit
tst_OpenCPUPolytomousGRM_itemfit_table_infit#:#infit
tst_OpenCPUPolytomousGRM_itemfit_table_z.infit#:#z.infit
tst_OpenCPUPolytomousGRM_itemfit_table_X2#:#X2
tst_OpenCPUPolytomousGRM_itemfit_table_df.X2#:#df.X2
tst_OpenCPUPolytomousGRM_itemfit_table_RMSEA.X2#:#RMSEA.X2
tst_OpenCPUPolytomousGRM_itemfit_table_p.X2#:#p.X2
tst_OpenCPUPolytomousGRM_itemfit_table_G2#:#G2
tst_OpenCPUPolytomousGRM_itemfit_table_df.G2#:#df.G2
tst_OpenCPUPolytomousGRM_itemfit_table_RMSEA.G2#:#RMSEA.G2
tst_OpenCPUPolytomousGRM_itemfit_table_p.G2#:#p.G2
tst_OpenCPUPolytomousGRM_itemfit_table_S_X2#:#S_X2
tst_OpenCPUPolytomousGRM_itemfit_table_df.S_X2#:#df.S_X2
tst_OpenCPUPolytomousGRM_itemfit_table_RMSEA.S_X2#:#RMSEA.S_X2
tst_OpenCPUPolytomousGRM_itemfit_table_p.S_X2#:#p.S_X2